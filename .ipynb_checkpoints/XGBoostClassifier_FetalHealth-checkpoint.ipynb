{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "247bcea9",
   "metadata": {},
   "source": [
    "For XGB reference \n",
    "    \n",
    "- https://towardsdatascience.com/beginners-guide-to-xgboost-for-classification-problems-50f75aac5390\n",
    "\n",
    "\n",
    "- Using XGBoost in Pipelines : https://goodboychan.github.io/python/datacamp/machine_learning/2020/07/07/03-Using-XGBoost-in-pipelines.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87690706",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:21:38.032349Z",
     "start_time": "2022-12-01T11:21:38.016399Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score,confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, StratifiedKFold\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee3e030d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:21:38.221332Z",
     "start_time": "2022-12-01T11:21:38.208320Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e1075ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:21:38.454266Z",
     "start_time": "2022-12-01T11:21:38.410452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline value</th>\n",
       "      <th>accelerations</th>\n",
       "      <th>fetal_movement</th>\n",
       "      <th>uterine_contractions</th>\n",
       "      <th>light_decelerations</th>\n",
       "      <th>severe_decelerations</th>\n",
       "      <th>prolongued_decelerations</th>\n",
       "      <th>abnormal_short_term_variability</th>\n",
       "      <th>mean_value_of_short_term_variability</th>\n",
       "      <th>percentage_of_time_with_abnormal_long_term_variability</th>\n",
       "      <th>mean_value_of_long_term_variability</th>\n",
       "      <th>histogram_width</th>\n",
       "      <th>histogram_min</th>\n",
       "      <th>histogram_max</th>\n",
       "      <th>histogram_number_of_peaks</th>\n",
       "      <th>histogram_number_of_zeroes</th>\n",
       "      <th>histogram_mode</th>\n",
       "      <th>histogram_mean</th>\n",
       "      <th>histogram_median</th>\n",
       "      <th>histogram_variance</th>\n",
       "      <th>histogram_tendency</th>\n",
       "      <th>fetal_health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>64.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>117.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   baseline value  accelerations  fetal_movement  uterine_contractions  \\\n",
       "0           120.0          0.000             0.0                 0.000   \n",
       "1           132.0          0.006             0.0                 0.006   \n",
       "2           133.0          0.003             0.0                 0.008   \n",
       "3           134.0          0.003             0.0                 0.008   \n",
       "4           132.0          0.007             0.0                 0.008   \n",
       "\n",
       "   light_decelerations  severe_decelerations  prolongued_decelerations  \\\n",
       "0                0.000                   0.0                       0.0   \n",
       "1                0.003                   0.0                       0.0   \n",
       "2                0.003                   0.0                       0.0   \n",
       "3                0.003                   0.0                       0.0   \n",
       "4                0.000                   0.0                       0.0   \n",
       "\n",
       "   abnormal_short_term_variability  mean_value_of_short_term_variability  \\\n",
       "0                             73.0                                   0.5   \n",
       "1                             17.0                                   2.1   \n",
       "2                             16.0                                   2.1   \n",
       "3                             16.0                                   2.4   \n",
       "4                             16.0                                   2.4   \n",
       "\n",
       "   percentage_of_time_with_abnormal_long_term_variability  \\\n",
       "0                                               43.0        \n",
       "1                                                0.0        \n",
       "2                                                0.0        \n",
       "3                                                0.0        \n",
       "4                                                0.0        \n",
       "\n",
       "   mean_value_of_long_term_variability  histogram_width  histogram_min  \\\n",
       "0                                  2.4             64.0           62.0   \n",
       "1                                 10.4            130.0           68.0   \n",
       "2                                 13.4            130.0           68.0   \n",
       "3                                 23.0            117.0           53.0   \n",
       "4                                 19.9            117.0           53.0   \n",
       "\n",
       "   histogram_max  histogram_number_of_peaks  histogram_number_of_zeroes  \\\n",
       "0          126.0                        2.0                         0.0   \n",
       "1          198.0                        6.0                         1.0   \n",
       "2          198.0                        5.0                         1.0   \n",
       "3          170.0                       11.0                         0.0   \n",
       "4          170.0                        9.0                         0.0   \n",
       "\n",
       "   histogram_mode  histogram_mean  histogram_median  histogram_variance  \\\n",
       "0           120.0           137.0             121.0                73.0   \n",
       "1           141.0           136.0             140.0                12.0   \n",
       "2           141.0           135.0             138.0                13.0   \n",
       "3           137.0           134.0             137.0                13.0   \n",
       "4           137.0           136.0             138.0                11.0   \n",
       "\n",
       "   histogram_tendency  fetal_health  \n",
       "0                 1.0           2.0  \n",
       "1                 0.0           1.0  \n",
       "2                 0.0           1.0  \n",
       "3                 1.0           1.0  \n",
       "4                 1.0           1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv('fetal_health.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84accb26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:21:38.624481Z",
     "start_time": "2022-12-01T11:21:38.612486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2126, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2dd134b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:21:38.842090Z",
     "start_time": "2022-12-01T11:21:38.823925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2126, 21), (2126,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee97cc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:21:39.028563Z",
     "start_time": "2022-12-01T11:21:39.004314Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1700, 21), (426, 21), (1700,), (426,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=y,random_state=45)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "926e77cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:21:39.184654Z",
     "start_time": "2022-12-01T11:21:39.174737Z"
    }
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ff1bb5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:21:39.354365Z",
     "start_time": "2022-12-01T11:21:39.340380Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps = [\n",
    "    ('scaler',MinMaxScaler()),\n",
    "    ('model',model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "128c2e4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:21:39.525222Z",
     "start_time": "2022-12-01T11:21:39.512227Z"
    }
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27fd2aa0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:21:46.957564Z",
     "start_time": "2022-12-01T11:21:39.686747Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    6.7s remaining:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8907653467977678"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(pipe,X,y,cv=skf,n_jobs=-1,verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61cf03ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:21:46.989554Z",
     "start_time": "2022-12-01T11:21:46.962561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method XGBModel.get_params of XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None,\n",
       "              enable_categorical=False, gamma=None, gpu_id=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, reg_alpha=None,\n",
       "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "              tree_method=None, validate_parameters=None, verbosity=None)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e95c124f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:21:47.005559Z",
     "start_time": "2022-12-01T11:21:46.992554Z"
    }
   },
   "outputs": [],
   "source": [
    "max_depth = [3, 4, 5, 7]\n",
    "learning_rate = [0.1, 0.01, 0.05]\n",
    "gamma = [0, 0.25, 1]\n",
    "scale_pos_weight = [1, 3, 5]\n",
    "subsample = [0.8]\n",
    "colsample_bytree = [0.6,0.8]\n",
    "n_estimators = [200,500,600]\n",
    "min_child_weight = [50,70,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec96c273",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:21:47.021124Z",
     "start_time": "2022-12-01T11:21:47.010549Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\": max_depth,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"gamma\": gamma,\n",
    "    \"scale_pos_weight\": scale_pos_weight,\n",
    "    \"subsample\": subsample,\n",
    "    \"colsample_bytree\": colsample_bytree,\n",
    "    \"n_estimators\" : n_estimators,\n",
    "    \"min_child_weight\" : min_child_weight\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "280543a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T11:21:47.037104Z",
     "start_time": "2022-12-01T11:21:47.024115Z"
    }
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8afabf75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T14:13:16.379248Z",
     "start_time": "2022-12-01T14:13:16.373239Z"
    }
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ea8e113",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T14:17:20.955789Z",
     "start_time": "2022-12-01T14:17:20.939806Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps = [\n",
    "    ('scaler',MinMaxScaler()),\n",
    "    ('model',model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a438e5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T14:16:56.838839Z",
     "start_time": "2022-12-01T14:16:56.827839Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_xgb = GridSearchCV(pipe,param_grid=param_grid,n_jobs=-1,verbose=1,return_train_score=True,cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92c2c514",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T14:16:57.180414Z",
     "start_time": "2022-12-01T14:16:57.170400Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_xgb = GridSearchCV(estimator=xgb.XGBClassifier(),param_grid=param_grid,scoring='accuracy',n_jobs=-1,verbose=1,return_train_score=True,cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e09a8ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T13:37:41.508714Z",
     "start_time": "2022-12-01T11:21:47.088113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 324 candidates, totalling 3240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:07:40] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[19:07:40] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     enable_categorical=False, gamma=None,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, m...\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.5], 'gamma': [0, 0.25, 1],\n",
       "                         'learning_rate': [0.1, 0.01, 0.05],\n",
       "                         'max_depth': [3, 4, 5, 7],\n",
       "                         'n_estimators': [200, 500, 600],\n",
       "                         'scale_pos_weight': [1, 3, 5], 'subsample': [0.8]},\n",
       "             return_train_score=True, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_xgb.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39c1fbca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T13:37:41.540274Z",
     "start_time": "2022-12-01T13:37:41.517656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9025445123571618"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_xgb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f95c957",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T13:37:41.555661Z",
     "start_time": "2022-12-01T13:37:41.543276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'gamma': 0,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 3,\n",
       " 'n_estimators': 200,\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c076e2f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T13:37:41.618081Z",
     "start_time": "2022-12-01T13:37:41.558576Z"
    }
   },
   "outputs": [],
   "source": [
    "hyper_df = pd.DataFrame(grid_xgb.cv_results_).sort_values(by='mean_test_score',ascending=False)\n",
    "hyper_df.to_csv('hyperparamter_xgb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a51c74ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T13:37:41.695596Z",
     "start_time": "2022-12-01T13:37:41.622084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_scale_pos_weight</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.152400</td>\n",
       "      <td>1.194542</td>\n",
       "      <td>0.011808</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'gamma': 0, 'learnin...</td>\n",
       "      <td>0.896714</td>\n",
       "      <td>0.934272</td>\n",
       "      <td>0.938967</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.910377</td>\n",
       "      <td>0.933962</td>\n",
       "      <td>0.858491</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.902545</td>\n",
       "      <td>0.067577</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995295</td>\n",
       "      <td>0.994773</td>\n",
       "      <td>0.993204</td>\n",
       "      <td>0.993727</td>\n",
       "      <td>0.992682</td>\n",
       "      <td>0.993727</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.993208</td>\n",
       "      <td>0.996343</td>\n",
       "      <td>0.994199</td>\n",
       "      <td>0.001057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.451464</td>\n",
       "      <td>0.179077</td>\n",
       "      <td>0.011255</td>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'gamma': 0, 'learnin...</td>\n",
       "      <td>0.896714</td>\n",
       "      <td>0.934272</td>\n",
       "      <td>0.938967</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.910377</td>\n",
       "      <td>0.933962</td>\n",
       "      <td>0.858491</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.902545</td>\n",
       "      <td>0.067577</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995295</td>\n",
       "      <td>0.994773</td>\n",
       "      <td>0.993204</td>\n",
       "      <td>0.993727</td>\n",
       "      <td>0.992682</td>\n",
       "      <td>0.993727</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.993208</td>\n",
       "      <td>0.996343</td>\n",
       "      <td>0.994199</td>\n",
       "      <td>0.001057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.715602</td>\n",
       "      <td>0.987348</td>\n",
       "      <td>0.017714</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'gamma': 0, 'learnin...</td>\n",
       "      <td>0.896714</td>\n",
       "      <td>0.934272</td>\n",
       "      <td>0.938967</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.910377</td>\n",
       "      <td>0.933962</td>\n",
       "      <td>0.858491</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.902545</td>\n",
       "      <td>0.067577</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995295</td>\n",
       "      <td>0.994773</td>\n",
       "      <td>0.993204</td>\n",
       "      <td>0.993727</td>\n",
       "      <td>0.992682</td>\n",
       "      <td>0.993727</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.993208</td>\n",
       "      <td>0.996343</td>\n",
       "      <td>0.994199</td>\n",
       "      <td>0.001057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>11.691577</td>\n",
       "      <td>0.103476</td>\n",
       "      <td>0.009166</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'gamma': 0.25, 'lear...</td>\n",
       "      <td>0.892019</td>\n",
       "      <td>0.924883</td>\n",
       "      <td>0.938967</td>\n",
       "      <td>0.924883</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.910377</td>\n",
       "      <td>0.938679</td>\n",
       "      <td>0.858491</td>\n",
       "      <td>0.721698</td>\n",
       "      <td>0.902079</td>\n",
       "      <td>0.066366</td>\n",
       "      <td>4</td>\n",
       "      <td>0.994250</td>\n",
       "      <td>0.994250</td>\n",
       "      <td>0.992682</td>\n",
       "      <td>0.992682</td>\n",
       "      <td>0.991636</td>\n",
       "      <td>0.992682</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.993730</td>\n",
       "      <td>0.993208</td>\n",
       "      <td>0.995820</td>\n",
       "      <td>0.993519</td>\n",
       "      <td>0.001127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>12.591749</td>\n",
       "      <td>0.354897</td>\n",
       "      <td>0.010607</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'gamma': 0.25, 'lear...</td>\n",
       "      <td>0.892019</td>\n",
       "      <td>0.924883</td>\n",
       "      <td>0.938967</td>\n",
       "      <td>0.924883</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.910377</td>\n",
       "      <td>0.938679</td>\n",
       "      <td>0.858491</td>\n",
       "      <td>0.721698</td>\n",
       "      <td>0.902079</td>\n",
       "      <td>0.066366</td>\n",
       "      <td>4</td>\n",
       "      <td>0.994250</td>\n",
       "      <td>0.994250</td>\n",
       "      <td>0.992682</td>\n",
       "      <td>0.992682</td>\n",
       "      <td>0.991636</td>\n",
       "      <td>0.992682</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.993730</td>\n",
       "      <td>0.993208</td>\n",
       "      <td>0.995820</td>\n",
       "      <td>0.993519</td>\n",
       "      <td>0.001127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>13.259716</td>\n",
       "      <td>0.206036</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'gamma': 0.25, 'lear...</td>\n",
       "      <td>0.892019</td>\n",
       "      <td>0.924883</td>\n",
       "      <td>0.938967</td>\n",
       "      <td>0.924883</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.910377</td>\n",
       "      <td>0.938679</td>\n",
       "      <td>0.858491</td>\n",
       "      <td>0.721698</td>\n",
       "      <td>0.902079</td>\n",
       "      <td>0.066366</td>\n",
       "      <td>4</td>\n",
       "      <td>0.994250</td>\n",
       "      <td>0.994250</td>\n",
       "      <td>0.992682</td>\n",
       "      <td>0.992682</td>\n",
       "      <td>0.991636</td>\n",
       "      <td>0.992682</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.993730</td>\n",
       "      <td>0.993208</td>\n",
       "      <td>0.995820</td>\n",
       "      <td>0.993519</td>\n",
       "      <td>0.001127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        13.152400      1.194542         0.011808        0.003599   \n",
       "2        12.451464      0.179077         0.011255        0.003458   \n",
       "1        13.715602      0.987348         0.017714        0.008200   \n",
       "108      11.691577      0.103476         0.009166        0.000935   \n",
       "109      12.591749      0.354897         0.010607        0.004559   \n",
       "110      13.259716      0.206036         0.009380        0.000630   \n",
       "\n",
       "    param_colsample_bytree param_gamma param_learning_rate param_max_depth  \\\n",
       "0                      0.5           0                 0.1               3   \n",
       "2                      0.5           0                 0.1               3   \n",
       "1                      0.5           0                 0.1               3   \n",
       "108                    0.5        0.25                 0.1               3   \n",
       "109                    0.5        0.25                 0.1               3   \n",
       "110                    0.5        0.25                 0.1               3   \n",
       "\n",
       "    param_n_estimators param_scale_pos_weight param_subsample  \\\n",
       "0                  200                      1             0.8   \n",
       "2                  200                      5             0.8   \n",
       "1                  200                      3             0.8   \n",
       "108                200                      1             0.8   \n",
       "109                200                      3             0.8   \n",
       "110                200                      5             0.8   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'colsample_bytree': 0.5, 'gamma': 0, 'learnin...           0.896714   \n",
       "2    {'colsample_bytree': 0.5, 'gamma': 0, 'learnin...           0.896714   \n",
       "1    {'colsample_bytree': 0.5, 'gamma': 0, 'learnin...           0.896714   \n",
       "108  {'colsample_bytree': 0.5, 'gamma': 0.25, 'lear...           0.892019   \n",
       "109  {'colsample_bytree': 0.5, 'gamma': 0.25, 'lear...           0.892019   \n",
       "110  {'colsample_bytree': 0.5, 'gamma': 0.25, 'lear...           0.892019   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0             0.934272           0.938967           0.929577   \n",
       "2             0.934272           0.938967           0.929577   \n",
       "1             0.934272           0.938967           0.929577   \n",
       "108           0.924883           0.938967           0.924883   \n",
       "109           0.924883           0.938967           0.924883   \n",
       "110           0.924883           0.938967           0.924883   \n",
       "\n",
       "     split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0             0.948357           0.957746           0.910377   \n",
       "2             0.948357           0.957746           0.910377   \n",
       "1             0.948357           0.957746           0.910377   \n",
       "108           0.953052           0.957746           0.910377   \n",
       "109           0.953052           0.957746           0.910377   \n",
       "110           0.953052           0.957746           0.910377   \n",
       "\n",
       "     split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0             0.933962           0.858491           0.716981         0.902545   \n",
       "2             0.933962           0.858491           0.716981         0.902545   \n",
       "1             0.933962           0.858491           0.716981         0.902545   \n",
       "108           0.938679           0.858491           0.721698         0.902079   \n",
       "109           0.938679           0.858491           0.721698         0.902079   \n",
       "110           0.938679           0.858491           0.721698         0.902079   \n",
       "\n",
       "     std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0          0.067577                1            0.995295            0.994773   \n",
       "2          0.067577                1            0.995295            0.994773   \n",
       "1          0.067577                1            0.995295            0.994773   \n",
       "108        0.066366                4            0.994250            0.994250   \n",
       "109        0.066366                4            0.994250            0.994250   \n",
       "110        0.066366                4            0.994250            0.994250   \n",
       "\n",
       "     split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0              0.993204            0.993727            0.992682   \n",
       "2              0.993204            0.993727            0.992682   \n",
       "1              0.993204            0.993727            0.992682   \n",
       "108            0.992682            0.992682            0.991636   \n",
       "109            0.992682            0.992682            0.991636   \n",
       "110            0.992682            0.992682            0.991636   \n",
       "\n",
       "     split5_train_score  split6_train_score  split7_train_score  \\\n",
       "0              0.993727            0.994775            0.994253   \n",
       "2              0.993727            0.994775            0.994253   \n",
       "1              0.993727            0.994775            0.994253   \n",
       "108            0.992682            0.994253            0.993730   \n",
       "109            0.992682            0.994253            0.993730   \n",
       "110            0.992682            0.994253            0.993730   \n",
       "\n",
       "     split8_train_score  split9_train_score  mean_train_score  std_train_score  \n",
       "0              0.993208            0.996343          0.994199         0.001057  \n",
       "2              0.993208            0.996343          0.994199         0.001057  \n",
       "1              0.993208            0.996343          0.994199         0.001057  \n",
       "108            0.993208            0.995820          0.993519         0.001127  \n",
       "109            0.993208            0.995820          0.993519         0.001127  \n",
       "110            0.993208            0.995820          0.993519         0.001127  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_df.head(6)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "689e4b37",
   "metadata": {},
   "source": [
    "model = xgb.XGBClassifier(colsample_bytree=0.5,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=2,\n",
    "                         gamma=1,\n",
    "                         learning_rate=0.1,\n",
    "                         max_depth=3,\n",
    "                         scale_pos_weight = 1,\n",
    "                          subsample = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e40ac0cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T14:19:10.746149Z",
     "start_time": "2022-12-01T14:19:10.734136Z"
    }
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(colsample_bytree=0.5,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=2,\n",
    "                          n_estimators=200,\n",
    "                         gamma=1,\n",
    "                         learning_rate=0.1,\n",
    "                         max_depth=3,\n",
    "                         scale_pos_weight = 1,\n",
    "                          subsample = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ea028638",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T14:19:12.034046Z",
     "start_time": "2022-12-01T14:19:11.029880Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:49:11] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[19:49:11] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                ('model',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=0.5, enable_categorical=False,\n",
       "                               gamma=0, gpu_id=-1, importance_type=None,\n",
       "                               interaction_constraints='', learning_rate=0.01,\n",
       "                               max_delta_step=0, max_depth=3,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=200,\n",
       "                               n_jobs=-1, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', predictor='auto',\n",
       "                               random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                               scale_pos_weight=1, subsample=0.8,\n",
       "                               tree_method='exact', validate_parameters=1,\n",
       "                               verbose=2, verbosity=None))])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8711511a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T14:19:12.065614Z",
     "start_time": "2022-12-01T14:19:12.037043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 2., 1., 1., 3., 3., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 3., 1., 1., 2., 1., 1., 3., 1., 1., 1., 1., 1., 2., 1.,\n",
       "       1., 1., 1., 1., 2., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 2., 1., 3., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 3., 1., 3., 1., 1., 1., 1., 1., 2., 1., 1., 2., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 2., 3., 1., 2.,\n",
       "       1., 1., 1., 1., 1., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       3., 1., 1., 1., 1., 2., 1., 3., 1., 1., 1., 1., 1., 1., 2., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 3., 1., 1., 1., 1., 1., 1., 3., 1., 3., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 2., 1., 1., 1., 3., 3., 1., 3., 1., 2., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1.,\n",
       "       1., 1., 1., 2., 2., 2., 1., 1., 1., 3., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 3., 1., 1., 1., 1., 1., 1., 2., 1., 3., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 3., 2., 1., 2., 3.,\n",
       "       1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 3., 1., 1., 1., 1.,\n",
       "       1., 2., 1., 1., 3., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 3., 1., 2., 2., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 2., 1., 1., 2., 1., 1., 1., 1., 1., 1., 3., 1., 1.,\n",
       "       1., 1., 1., 2., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1.,\n",
       "       3., 3., 2., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       3., 1., 1., 1., 1., 1., 1., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 3., 1., 1., 1., 1., 1., 3., 1.,\n",
       "       1., 1., 1., 1., 2., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1.,\n",
       "       1., 1., 1., 1., 3., 1., 1., 1., 1., 2., 1., 2., 1., 1., 1., 2., 1.,\n",
       "       1.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1eb67011",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T14:19:12.176429Z",
     "start_time": "2022-12-01T14:19:12.166505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing score of gradient Boosting :  95.070 %\n"
     ]
    }
   ],
   "source": [
    "print(\"testing score of gradient Boosting : \",\"%.3f\"%(accuracy_score(y_test,y_pred)*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a1a2d22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T14:19:13.472493Z",
     "start_time": "2022-12-01T14:19:13.444995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score of gradient Boosting :  94.059 %\n"
     ]
    }
   ],
   "source": [
    "print(\"training score of gradient Boosting : \",\"%.3f\"%(accuracy_score(y_train,pipe.predict(X_train))*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5cbf44e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T14:18:15.725933Z",
     "start_time": "2022-12-01T14:18:15.708950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.95      0.99      0.97       332\n",
      "         2.0       0.98      0.75      0.85        59\n",
      "         3.0       0.94      0.91      0.93        35\n",
      "\n",
      "    accuracy                           0.95       426\n",
      "   macro avg       0.96      0.88      0.91       426\n",
      "weighted avg       0.95      0.95      0.95       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_classifcation = classification_report(y_test,y_pred)\n",
    "print(xgb_classifcation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2652602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
